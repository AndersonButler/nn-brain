{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "In this notebook, we will cover training a simple convolutional neural network on the MNIST dataset, visualizing tuning of model neurons, computing representational similarity analysis (RSA) for different model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset\n",
    "\n",
    "We will use the classical MNIST dataset because it allows rapid training on CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST dataset\n",
    "path = Path('./')\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,)),\n",
    "     ])\n",
    "trainset = datasets.MNIST(path, train=True, download=True,transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True)\n",
    "\n",
    "testset = datasets.MNIST(path, train=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of images from one batch :  torch.Size([16, 1, 28, 28])\n",
      "Shape of labels from one batch :  torch.Size([16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label 8')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize an image from the dataset\n",
    "for i, data in enumerate(train_loader):\n",
    "    images, labels = data\n",
    "    break\n",
    "print('Shape of images from one batch : ', image.shape)\n",
    "print('Shape of labels from one batch : ', label.shape)\n",
    "\n",
    "plt.imshow(image[0, 0])\n",
    "plt.title('Label {}'.format(label[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 7*7 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "        # Set whether to readout activation\n",
    "        self.readout = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        l1 = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        l2 = F.max_pool2d(F.relu(self.conv2(l1)), 2)\n",
    "        l2_flat = torch.flatten(l2, start_dim=1)  # flatten tensor, while keeping batch dimension\n",
    "        l3 = F.relu(self.fc1(l2_flat))\n",
    "        l4 = F.relu(self.fc2(l3))\n",
    "        y = self.fc3(l4)\n",
    "        \n",
    "        if self.readout:\n",
    "            return {'l1': l1, 'l2': l2, 'l3': l3, 'l4': l4}\n",
    "        else:\n",
    "            return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "The following code trains the above network on MNIST until it reaches 95% accuracy. It should take only ~500-1000 training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Step 100, Loss 1.0973, Acc 0.619\n",
      "Step 200, Loss 0.3502, Acc 0.892\n",
      "Step 300, Loss 0.2853, Acc 0.918\n",
      "Step 400, Loss 0.2911, Acc 0.917\n",
      "Step 500, Loss 0.2618, Acc 0.921\n",
      "Step 600, Loss 0.2794, Acc 0.920\n",
      "Step 700, Loss 0.2071, Acc 0.941\n",
      "Step 800, Loss 0.2363, Acc 0.934\n",
      "Step 900, Loss 0.2160, Acc 0.941\n",
      "Step 1000, Loss 0.2226, Acc 0.934\n",
      "Step 1100, Loss 0.1897, Acc 0.952\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Instantiate the network and print information\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "running_loss = 0\n",
    "running_acc = 0\n",
    "for i, data in enumerate(train_loader):\n",
    "    image, label = data\n",
    "\n",
    "    # in your training loop:\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    output = net(image)\n",
    "    loss = criterion(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()    # Does the update\n",
    "\n",
    "    # prediction\n",
    "    prediction = torch.argmax(output, axis=-1)\n",
    "    acc = torch.mean((label == prediction).float())\n",
    "\n",
    "    running_loss += loss.item()\n",
    "    running_acc += acc\n",
    "    if i % 100 == 99:\n",
    "        running_loss /= 100\n",
    "        running_acc /= 100\n",
    "        print('Step {}, Loss {:0.4f}, Acc {:0.3f}'.format(\n",
    "            i+1, running_loss, running_acc))\n",
    "        if running_acc > 0.95:\n",
    "            break\n",
    "        running_loss, running_acc = 0, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute representation similarity\n",
    "\n",
    "We will first compute the neural responses to a batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(test_loader):\n",
    "    images, labels = data\n",
    "    break\n",
    "\n",
    "# Readout network activity\n",
    "net.readout = True\n",
    "activity = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 6, 13, 13])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activity['l1'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for preferred stimulus for a given neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
